#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Oct  8 14:35:59 2019

@author: Ary
"""

import pandas as pd
import os
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score

#set a random seed
np.random.seed(0)

#read data and create a dataframe
cwd = os.getcwd()
filename = cwd + '/default of credit card clients.xls'
nanDict = {}
df = pd.read_excel(filename, header=1, skiprows=0, index_col=0, na_values=nanDict)

df.rename(index=str, columns={"default payment next month": "defaultPaymentNextMonth"}, inplace=True)

# Features and targets 
X = df.loc[:, df.columns != 'defaultPaymentNextMonth'].values
y = df.loc[:, df.columns == 'defaultPaymentNextMonth'].values
y = np.ravel(y)

#build design matrix
n_columns = 24
X_1 = np.zeros((X.shape[0],n_columns))
X_1[:,0] = np.ones((X.shape[0]))
X_1[:,1:] = X
#print(pd.DataFrame(X_1))

#gradient descent method to estimate betas
betas = np.random.randn(X_1.shape[1])
gamma = 0.01
epsilon = 1e-2
gradient_norm = 1
p = np.zeros((X_1.shape[0]))
while gradient_norm > epsilon:      
    for i in range(X_1.shape[0]):
        print((1+np.exp(X_1[i,:].dot(betas))), end='')
        p[i] = (np.exp(betas.dot(X_1[i,:])))/(1+np.exp(betas.dot(X_1[i,:])))
    gradient = -(np.transpose(X_1)).dot(y-p)
    betas = betas - gamma*gradient
    gradient_norm = np.linalg.norm(gradient)
# =============================================================================
# print(betas.shape, X_1.shape)
# print(p.shape)


for i in range(X_1.shape[0]):
    p[i] = (np.exp(betas.dot(X_1[i,:])))/(1+np.exp(betas.dot(X_1[i,:])))

print(p, y)
